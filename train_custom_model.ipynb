{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfq+9md61nbW5DjAmsHVq4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejunga/ML-Vehicle_Image_Classification/blob/main/train_custom_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDAofhrYdaWM",
        "outputId": "31c6b516-1c57-42e5-ed38-b7e4442a5ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3911 images belonging to 7 classes.\n",
            "Found 838 images belonging to 7 classes.\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m 99/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m5:21\u001b[0m 13s/step - accuracy: 0.3752 - loss: 2.6414"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2102s\u001b[0m 16s/step - accuracy: 0.3857 - loss: 2.4998 - val_accuracy: 0.1432 - val_loss: 10.4180 - learning_rate: 1.0000e-04\n",
            "Epoch 2/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 579ms/step - accuracy: 0.5167 - loss: 1.3624 - val_accuracy: 0.1850 - val_loss: 10.8951 - learning_rate: 1.0000e-04\n",
            "Epoch 3/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 574ms/step - accuracy: 0.5788 - loss: 1.2115 - val_accuracy: 0.2387 - val_loss: 5.2198 - learning_rate: 1.0000e-04\n",
            "Epoch 4/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 572ms/step - accuracy: 0.6044 - loss: 1.1435 - val_accuracy: 0.5823 - val_loss: 1.4269 - learning_rate: 1.0000e-04\n",
            "Epoch 5/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 567ms/step - accuracy: 0.6313 - loss: 1.0603 - val_accuracy: 0.6874 - val_loss: 0.8823 - learning_rate: 1.0000e-04\n",
            "Epoch 6/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 569ms/step - accuracy: 0.6342 - loss: 1.0890 - val_accuracy: 0.7446 - val_loss: 0.7830 - learning_rate: 1.0000e-04\n",
            "Epoch 7/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 565ms/step - accuracy: 0.6439 - loss: 1.0057 - val_accuracy: 0.7327 - val_loss: 0.9399 - learning_rate: 1.0000e-04\n",
            "Epoch 8/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 658ms/step - accuracy: 0.6766 - loss: 0.9335 - val_accuracy: 0.7184 - val_loss: 0.9032 - learning_rate: 1.0000e-04\n",
            "Epoch 9/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 650ms/step - accuracy: 0.6817 - loss: 0.9099 - val_accuracy: 0.7434 - val_loss: 0.8454 - learning_rate: 1.0000e-04\n",
            "Epoch 10/10\n",
            "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 572ms/step - accuracy: 0.7004 - loss: 0.8792 - val_accuracy: 0.7697 - val_loss: 0.7733 - learning_rate: 5.0000e-05\n",
            "Custom model trained and saved to /content/drive/My Drive/models/custom_vehicle_model.keras successfully!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up directories for training data\n",
        "main_dir = \"/content/drive/My Drive/Vehicles\"\n",
        "categories = [\"Auto Rickshaws\", \"Bikes\", \"Cars\", \"Motorcycles\", \"Planes\", \"Ships\", \"Trains\"]\n",
        "base_split_dir = \"/content/drive/My Drive/vehicles_split\"\n",
        "\n",
        "# Custom neural network model with Batch Normalization and enhanced architecture\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer (smaller filter size) + Batch Normalization\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Second convolutional layer + Batch Normalization\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Third convolutional layer + Batch Normalization\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flattening the output for fully connected layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layer with fewer neurons + Dropout\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Output layer for classification\n",
        "model.add(Dense(len(categories), activation='softmax'))\n",
        "\n",
        "# Compile the model using Adam optimizer with a reduced learning rate\n",
        "optimizer = Adam(learning_rate=1e-4)  # You can experiment with different learning rates\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Create data generators with additional augmentations\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.3,  # Increased zoom augmentation\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'  # Filling in missing pixels after augmentation\n",
        ")\n",
        "\n",
        "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Ensure the directories exist before creating generators\n",
        "train_generator = train_datagen.flow_from_directory(os.path.join(base_split_dir, \"train\"),\n",
        "                                                    target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
        "val_generator = val_test_datagen.flow_from_directory(os.path.join(base_split_dir, \"val\"),\n",
        "                                                     target_size=(150, 150), batch_size=32, class_mode='categorical')\n",
        "\n",
        "# Callbacks for early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
        "\n",
        "# Train the model and save the history\n",
        "history = model.fit(train_generator, epochs=10, validation_data=val_generator,\n",
        "                    callbacks=[early_stopping, reduce_lr])  # Reduced learning rate if the validation loss plateaus\n",
        "\n",
        "# Save the training history\n",
        "history_save_path = '/content/drive/My Drive/models/custom_model_history.pkl'\n",
        "with open(history_save_path, 'wb') as file_pi:\n",
        "    pickle.dump(history.history, file_pi)\n",
        "\n",
        "# Save the custom model\n",
        "model_save_path = '/content/drive/My Drive/models/custom_vehicle_model.keras'\n",
        "model.save(model_save_path)\n",
        "\n",
        "print(f\"Custom model trained and saved to {model_save_path} successfully!\")"
      ]
    }
  ]
}